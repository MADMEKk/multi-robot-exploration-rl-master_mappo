algorithm:
  actor_hidden_dim_1: 512
  actor_hidden_dim_2: 512
  actor_lr: 0.0003
  batch_size: 2048
  buffer_size: 1000000
  clip_param: 0.2
  critic_hidden_dim_1: 512
  critic_hidden_dim_2: 512
  critic_lr: 0.001
  entropy_coef: 0.01
  gae_lambda: 0.95
  gamma: 0.99
  lr_decay_rate: 0.9999
  max_episodes_in_buffer: 50
  max_grad_norm: 0.5
  min_lr: 1.0e-05
  update_epochs: 4
  value_coef: 0.5
environment:
  collision_reward: -20.0
  excessive_rotation_penalty: -0.2
  exploration_grid_resolution: 0.5
  exploration_reward_scale: 0.5
  goal_radius: 0.5
  goal_reward: 20.0
  individual_exploration_scale: 0.2
  map_number: 1
  map_size: !!python/tuple
  - 20.0
  - 20.0
  max_acceptable_overlap: 0.2
  max_angular_vel: 0.5
  max_linear_vel: 0.6
  max_steps_per_episode: 500
  min_angular_vel: -0.5
  min_linear_vel: 0.05
  movement_reward: 0.2
  number_of_robots: 2
  overlap_penalty_scale: 0.3
  slow_movement_penalty: -0.5
  time_penalty: -0.1
experiment:
  checkpoint_dir: deep_learning_weights/mappo
  evaluate_interval: 100
  metrics_dir: training_metrics
  name: default_experiment
  num_episodes: 10000
  plot_interval: 50
  print_interval: 10
  save_best_only: false
  save_interval: 50
